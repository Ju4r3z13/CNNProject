# -*- coding: utf-8 -*-
"""Proect3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_vW5TmcGMt72iJDIfQTYTWjKpALr6JiU
"""

!pip install d2l

import time
import torch
import random
import numpy as np
import torch.nn as nn
import torch.optim as optim
from d2l import torch as d2l
from itertools import product
from google.colab import files                #Download the files, ERASE IF NOT RUNNING ON COLAB
import torch.nn.functional as F
from sklearn.datasets import fetch_openml
from sklearn.model_selection import KFold
from torch.utils.data import TensorDataset, DataLoader
'''
                                        Project 3: Machine Learning
                                Neural Networks and Convolutional Neural Networks
                                        Eduardo Juarez, exj220003
Implementation Notes:
  For the CNN class I had originallyimplemented the example on: https://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html.
    However the model was giving me some trouble when using the d2l trainer and every fix I made made the nn more complex to fix,
    so I ended up switching the base class from nn.Module for the one I used for my MLP class (d2l.Classifier),
    which is more like this: https://d2l.ai/chapter_convolutional-neural-networks/lenet.html
  In addition to this I also had to implement the training_step() and validation_step() to re-shape my CNN input, but in rare occasions
    it would still throw format errors so I added the re-shaping loops in the run_models() function, and I decided to keep the previous
    two functions just in case they were still needed. So expect to see the same logic for both functions and the loop.
  I kept the download of the files (commented in main) in case you have trouble getting the printed output. I did this because
    the output would only show the plots so I kept track of the hyperparameters by sending them to the files and downloading them afterwards.
  I used the KFold object from:
    https://www.w3schools.com/python/python_ml_cross_validation.asp#:~:text=fold%20cross%20validation.-,K%2DFold,set%20to%20evaluate%20the%20model.
'''
def set_seed(seed=42):                        #Function to ensure reproducibility
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)          #For the PyTorch GPU management
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
set_seed(42)                                  #Set the seed

def get_MNIST_dataset():                      #Load MNIST dataset
  X, y = fetch_openml('mnist_784', version=1, return_X_y=True)
  X = X / 255.0                               #Normalizing pixel values to [0,1]
  y = y.astype(int)                           #Converting the labels to integer values
                                              #Splitting into training (60K) and test (10K) sets
  X_train, X_test = X[:60000], X[60000:]
  y_train, y_test = y[:60000], y[60000:]
  input_size = 784                            #The (total) size of the input is 28x28 pixels
  num_outputs = 10                            #The number of outputs (labels) from 0-9
  X_train = torch.FloatTensor(X_train.values) #Converting to PyTorch tesnors as it is the required by the PyTorch library
  y_train = torch.LongTensor(y_train.values)  #Using .values because it returns Pandas DataFrames
  X_test = torch.FloatTensor(X_test.values)
  y_test = torch.LongTensor(y_test.values)
  return X_train, X_test, y_train, y_test, input_size, num_outputs

def get_CIFAR_dataset():                      #Load CIFAR-10 dataset
  X, y = fetch_openml('CIFAR_10', version=1, return_X_y=True, as_frame=False)
  X = X / 255.0                               #Normilizing pixel values to [0,1]
  y = y.astype(int)                           #Converting the labels to integer values
  X_train, X_test = X[:50000], X[50000:]      #Splitting into training (50K) and test (10K) sets
  y_train, y_test = y[:50000], y[50000:]
  input_size = 32 * 32 * 3                    #The (total) size of the inoputs is 32x32 pixels * 3 (RGB)
  num_outputs = 10                            #The number of outputs (labels) from 0-9
  X_train = torch.FloatTensor(X_train)        #Converting to PyTorch tesnors as it is the required by the PyTorch library
  y_train = torch.LongTensor(y_train)         #No use of .values because it returns NumPy arrays
  X_test = torch.FloatTensor(X_test)
  y_test = torch.LongTensor(y_test)
  return X_train, X_test, y_train, y_test, input_size, num_outputs

class MLP(d2l.Classifier):                    #Multi-Layer Perceptron (using Classifier as base class)
    def __init__(self, input_size, num_outputs, layers, dropout=0.0): #Initialization of MLP with given parameters
        super().__init__()                    #Constructor of Classifier
        self.save_hyperparameters()           #Saves the attributes for reproducibility and access
        net = [nn.Flatten()]                  #List of layers, first being a layer that converts tensors into vectors
        prev_size = input_size                #Input size assignment
        for size in layers:                   #For size of hidden layer
            net.append(nn.Linear(prev_size, size)) #Add a fully conected layer of neurons
            net.append(nn.ReLU())             #Add a ReLU activation function
            if dropout > 0:                   #Add a dropout layer if given
                net.append(nn.Dropout(dropout)) #Dropout to prevent overfitting
            prev_size = size                  #Update the prev_size t current size
        net.append(nn.Linear(prev_size, num_outputs)) #Add output layer
        self.net = nn.Sequential(*net)        #Assign all layers as a sequential model element of the class

    def set_optimizer(self, optimizer, lr):   #Setting the optimizer and learning rate
      self.lr = lr                            #Assigning the learning rate to the model
      if optimizer == 'sgd':                  #Assigning the optimizer depending on type
        self.optimizer = torch.optim.SGD(self.net.parameters(), lr=self.lr)
      elif optimizer == 'adam':
        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=self.lr)

class CNN(d2l.Classifier):                    #Convolutional Neural Network (using Classifier as base class)
  def __init__(self, architecture, num_classes, lr, input_channels, dropout_rate): #Initialization of CNN with given parameters
    super().__init__()                        #Constructor of Classifier
    self.save_hyperparameters()               #Saves the attributes for reproducibility and access
    self.architecture_type = architecture     #Defining the architecture type for implementation
    self.loss_fn = nn.CrossEntropyLoss()      #Defining the loss function
    if architecture == "Baseline":            #Implementing the architechture
      self.net = self.baseline_cnn(input_channels, num_classes)
    elif architecture == "Enhanced":
      self.net = self.enhanced_cnn(input_channels, num_classes, dropout_rate)
    else:
      self.net = self.deeper_cnn(input_channels, num_classes, dropout_rate)

  def baseline_cnn(self, input_channels, num_classes): #Implementing a baseline architecture
    if self.input_channels == 1:
      return nn.Sequential(                   #Assign all layers as a sequential model element of the class
        nn.Conv2d(input_channels, 32, kernel_size=5, padding=2), nn.ReLU(), #First 2D convolution layer (with 32 filters)
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Conv2d(32, 64, kernel_size=5, padding=2), nn.ReLU(), #Second 2D convolution layer (with 64 filters)
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Flatten(),                         #Converts tensors into vectors
        nn.Linear(64 * 7 * 7, 128), nn.ReLU(), #Add a fully conected layer of neurons
        nn.Linear(128, num_classes))          #Add output layer
    else:
      return nn.Sequential(                   #Assign all layers as a sequential model element of the class
        nn.Conv2d(input_channels, 32, kernel_size=5, padding=2), nn.ReLU(), #First 2D convolution layer (with 32 filters)
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Conv2d(32, 64, kernel_size=5, padding=2), nn.ReLU(), #Second 2D convolution layer (with 64 filters)
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Flatten(),                         #Converts tensors into vectors
        nn.Linear(64 * 8 * 8, 128), nn.ReLU(), #Add a fully conected layer of neurons
        nn.Linear(128, num_classes))          #Add output layer
  def enhanced_cnn(self, input_channels, num_classes, dropout_rate): #Implementing enhanced architecture
    if self.input_channels == 1:
      return nn.Sequential(                   #Assign all layers as a sequential model element of the class
        nn.Conv2d(input_channels, 32, kernel_size=5, padding=2), #First 2D convolution layer (with 32 filters)
        nn.BatchNorm2d(32), nn.ReLU(),        #Batch normalization
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Conv2d(32, 64, kernel_size=5, padding=2), #Second 2D convolution layer (with 64 filters)
        nn.BatchNorm2d(64), nn.ReLU(),        #Batch normalization
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Flatten(),                         #Converts tensors into vectors
        nn.Linear(64 * 7 * 7, 128), nn.ReLU(), #Add a fully conected layer of neurons
        nn.Dropout(dropout_rate),             #Dropout to prevent overfitting
        nn.Linear(128, num_classes))          #Add output layer
    else:
      return nn.Sequential(                   #Assign all layers as a sequential model element of the class
        nn.Conv2d(input_channels, 32, kernel_size=5, padding=2), #First 2D convolution layer (with 32 filters)
        nn.BatchNorm2d(32), nn.ReLU(),        #Batch normalization
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Conv2d(32, 64, kernel_size=5, padding=2), #Second 2D convolution layer (with 64 filters)
        nn.BatchNorm2d(64), nn.ReLU(),        #Batch normalization
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Flatten(),                         #Converts tensors into vectors
        nn.Linear(64 * 8 * 8, 128), nn.ReLU(), #Add a fully conected layer of neurons
        nn.Dropout(dropout_rate),             #Dropout to prevent overfitting
        nn.Linear(128, num_classes))          #Add output layer
  def deeper_cnn(self, input_channels, num_classes, dropout_rate): #Implementating a deeper architecture
    if self.input_channels == 1:
      return nn.Sequential(                   #Assign all layers as a sequential model element of the class
        nn.Conv2d(input_channels, 32, kernel_size=3, padding=1), #First 2D convolution layer (with 32 filters)
        nn.BatchNorm2d(32), nn.ReLU(),        #Batch normalization
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Conv2d(32, 64, kernel_size=3, padding=1), #Second 2D convolution layer (with 32 filters)
        nn.BatchNorm2d(64), nn.ReLU(),        #Batch normalization
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Conv2d(64, 128, kernel_size=3, padding=1), #Third 2D convolution layer (with 64 filters)
        nn.BatchNorm2d(128), nn.ReLU(),       #Batch normalization
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Flatten(),                         #Converts tensors into vectors
        nn.Linear(128 * 3 * 3, 256), nn.ReLU(), #Add a fully conected layer of neurons
        nn.Dropout(dropout_rate),             #Dropout to prevent overfitting
        nn.Linear(256, num_classes))          #Add output layer
    else:
      return nn.Sequential(                   #Assign all layers as a sequential model element of the class
        nn.Conv2d(input_channels, 32, kernel_size=3, padding=1), #First 2D convolution layer (with 32 filters)
        nn.BatchNorm2d(32), nn.ReLU(),        #Batch normalization
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Conv2d(32, 64, kernel_size=3, padding=1), #Second 2D convolution layer (with 32 filters)
        nn.BatchNorm2d(64), nn.ReLU(),        #Batch normalization
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Conv2d(64, 128, kernel_size=3, padding=1), #Third 2D convolution layer (with 64 filters)
        nn.BatchNorm2d(128), nn.ReLU(),       #Batch normalization
        nn.MaxPool2d(kernel_size=2),          #Pooling layer
        nn.Flatten(),                         #Converts tensors into vectors
        nn.Linear(128 * 4 * 4, 256), nn.ReLU(), #Add a fully conected layer of neurons
        nn.Dropout(dropout_rate),             #Dropout to prevent overfitting
        nn.Linear(256, num_classes))          #Add output layer
  def forward(self, x):                       #Apply the model to the input
    return self.net(x)
  def set_optimizer(self, optimizer, lr):     #Setting the optimizer and learning rate
    self.lr = lr                              #Assigning the learning rate to the model
    if optimizer.lower() == 'sgd':            #Assigning the optimizer depending on type
      self.optimizer = torch.optim.SGD(self.parameters(), lr=lr)
    else:
      self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)
  def training_step(self, batch):             #Implemented these two functions to reshape when receiving data
    X, y = batch                              #Unpack data X and labels y
    if X.dim() == 2:                          #Re-shape if the input is flat
      if self.input_channels == 1:            #If MNIST:
        X = X.view(-1, self.input_channels, 28, 28) #Re-shape
      elif self.input_channels == 3:          #If CIFAR-10:
        X = X.view(-1, self.input_channels, 32, 32) #Re-shape
    return super().training_step((X, y))
  def validation_step(self, batch):           #Same logic as above but for validation step
    X, y = batch
    if X.dim() == 2:
      if self.input_channels == 1:
        X = X.view(-1, self.input_channels, 28, 28)
      elif self.input_channels == 3:
        X = X.view(-1, self.input_channels, 32, 32)
    return super().validation_step((X, y))
                                              #Driver for the models
def run_models(model_name, dataset_name, f, X_test, y_test, X_train, y_train, input_size, num_outputs):
  print(f"Using set: {dataset_name}", file=f)
  if model_name == "MLP":                     #Architecture list for MLP
    print("<<<<<<<<<<<<<<<<<<<<<<<<< MULTI-LAYER PERCEPTRON >>>>>>>>>>>>>>>>>>>>>>>>>", file=f)
    architecture_list = [([128], "Shallow"),  #Architecture list + label for print statement
                       ([512, 256, 128], "Medium-depth"),
                       ([2048, 1024, 512, 256, 128], "Deep")]
  else:                                       #Architecture list for CNN
    print("<<<<<<<<<<<<<<<<<<<<<< CONVOLUTIONAL NEURAL NETWORK >>>>>>>>>>>>>>>>>>>>>>", file=f)
    architecture_list = [("Baseline", "Baseline CNN")]
    input_channels = 1 if dataset_name == "MNIST" else 3 #Assigning input channels depending on the dataset
  learning_r_list = [0.001]             #Hyperparameters listed
  batch_size_list = [32]
  optimizer_list = ['adam']
  dropout_rate_list = [0.0]
  if model_name == "CNN":                     #Repeated logic to re-shape the datasets for CNN
    input_channels = 1 if dataset_name == "MNIST" else 3 #Assigning input channels depending on the dataset
    if dataset_name == "MNIST":               #For MNIST dataset
      X_train = X_train.view(-1, input_channels, 28, 28) #For train set
      X_test = X_test.view(-1, input_channels, 28, 28) #For test set
    else:                                     #For CIFAR-10 dataset
      X_train = X_train.view(-1, input_channels, 32, 32) #For train set
      X_test = X_test.view(-1, input_channels, 32, 32) #For test set
  results = []                                #List to store the results of tuning
  for layers, label in architecture_list:     #For each of the three architectures
    start_time = time.time()
    best_hyperparameters = {              #Store the best hyperparameters
            "architecture_label": 'Deeper CNN',
            "architecture": "Deeper",
            "learn_r": 0.001,
            "batch_size": 32,
            "optimizer": 'adam',
            "dropout": 0.3}
    print(f"{best_hyperparameters}", file=f)  #Repeating the process to retrain the model on the full training set
    train_dataset = TensorDataset(X_train, y_train) #Using the stored best hyperparameters
    print(f"Debug - best_hyperparameters before train_loader: {best_hyperparameters}")
    train_loader = DataLoader(train_dataset, batch_size=best_hyperparameters["batch_size"], shuffle=True)
    test_dataset = TensorDataset(X_test, y_test)
    test_loader = DataLoader(test_dataset, batch_size=best_hyperparameters["batch_size"])
    if model_name == "MLP":                   #Implementing MLP
      best_model = MLP(input_size=input_size, num_outputs=num_outputs,
                       layers=best_hyperparameters["architecture"],
                       dropout=best_hyperparameters["dropout"])
      best_model.set_optimizer(optimizer=best_hyperparameters["optimizer"], lr=best_hyperparameters["learn_r"])
    else:                                     #Implementing CNN
      best_model = CNN(architecture=best_hyperparameters["architecture_label"], num_classes=num_outputs,
                       lr=best_hyperparameters["learn_r"], input_channels=input_channels,
                       dropout_rate=best_hyperparameters["dropout"])
      best_model.set_optimizer(optimizer=best_hyperparameters["optimizer"], lr=best_hyperparameters["learn_r"])
    trainer = d2l.Trainer(max_epochs=20)
    data = d2l.DataModule()
    data.train_dataloader = lambda: train_loader
    data.val_dataloader = lambda: train_loader #Reusing train_loader as the function always expects the val_loader
    trainer.fit(best_model, data)             #Retraining the model
    best_model.eval()
    correct = 0
    total = 0
    with torch.no_grad():                     #Re-validating but using the test set
      for inputs, labels in test_loader:
        outputs = best_model(inputs)
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)
    test_accuracy = correct / total
    end_time = time.time()                    #End the timer
    total_time = end_time - start_time        #Getting total time
    print(f"Time taken for {label} architecture: {total_time:.2f} seconds. Accuracy: {test_accuracy:.4f}", file=f)
  print("<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n", file=f)
  return None

def main():
  #MNIST_X_train, MNIST_X_test, MNIST_y_train, MNIST_y_test, MNIST_inputs, MNIST_outputs = get_MNIST_dataset()
  CIFAR_X_train, CIFAR_X_test, CIFAR_y_train, CIFAR_y_test, CIFAR_inputs, CIFAR_outputs = get_CIFAR_dataset()
  '''with open("MLP_MNIST_outputs.txt", 'a') as f1:
    run_models("MLP", "MNIST", f1, MNIST_X_test, MNIST_y_test, MNIST_X_train, MNIST_y_train, MNIST_inputs, MNIST_outputs)
  #files.download('MLP_MNIST_outputsnew.txt')
  with open("MLP_CIFAR_outputs.txt", 'a') as f2:
    run_models("MLP", "CIFAR", f2, CIFAR_X_test, CIFAR_y_test, CIFAR_X_train, CIFAR_y_train, CIFAR_inputs, CIFAR_outputs)
  #files.download('MLP_CIFAR_outputs.txt')
  with open("CNN_MNIST_outputs.txt", 'a') as f3:
    run_models("CNN", "MNIST", f3,MNIST_X_test, MNIST_y_test, MNIST_X_train, MNIST_y_train, MNIST_inputs, MNIST_outputs)
  #files.download('CNN_MNIST_outputs.txt')'''
  with open("CNN_CIFAR_outputs.txt", 'a') as f4:
    run_models("CNN", "CIFAR", f4, CIFAR_X_test, CIFAR_y_test, CIFAR_X_train, CIFAR_y_train, CIFAR_inputs, CIFAR_outputs)
  files.download('CNN_CIFAR_outputs.txt')
  return None

if __name__ == "__main__":
  main()
